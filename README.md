# py_asyncio_demo_webscrape
Demonstrate <B>asyncio</B> experience, scrape websites, store and process data

# Project Idea: Asynchronous Web Scraper

## Description:

Build an asynchronous web scraper using Python's asyncio library. This project will allow you to fetch data from multiple websites simultaneously, improving performance and reducing the overall time required for scraping.

## Keywords:
asyncio, asynchronous, Python3, scraping, ETL, Flask

## Features:

### User Input: 
* Provide an interface for the user to enter a list of URLs they want to scrape.

### Asynchronous Requests: 
* Utilize the asyncio library to send asynchronous HTTP requests to the provided URLs.

### Parsing and Extracting: 
* Use a HTML parser library like BeautifulSoup or lxml to extract relevant data from the fetched web pages.

### Data Storage: 
* Store the extracted data in a structured format, such as a CSV file or a database.

### Error Handling: 
* Implement proper error handling for cases like network errors or invalid URLs.

### Throttling and Rate Limiting: 
* Implement throttling mechanisms to control the rate of requests to avoid overwhelming the server or getting blocked.

### User-Friendly Output: 
* Display the scraped data in a readable format, such as a console output or a simple web interface.

## Benefits: 
By building this project, you'll demonstrate your ability to work with asynchronous programming using asyncio, handle network requests efficiently, parse HTML content, and manage errors effectively. Additionally, it will showcase your understanding of best practices in web scraping and data storage.

# Progress

* async backend - Flesh out async portions